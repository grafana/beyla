version: '3.8'

services:
  testserver:
    build:
      context: ../..
      dockerfile: test/integration/components/testserver/Dockerfile
    image: hatest-testserver
    ports:
      - "8080:8080"
    environment:
      LOG_LEVEL: DEBUG
    depends_on:
      otelcol:
        condition: service_started
      jaeger:
        condition: service_started

  # another instance of the above image. Used to test the deduplication
  # of metrics when they come from the same executable file
  testserver-unused:
    image: hatest-testserver
    ports:
      - "38080:8080"
    environment:
      LOG_LEVEL: DEBUG

  testserver1:
    build:
      context: ../..
      dockerfile: test/integration/components/testserver/Dockerfile_rename1
    image: hatest-testserver1
    ports:
      - "8900:8900"
    environment:
      LOG_LEVEL: DEBUG
      
  # image that runs two instances of the 'testserver' executable
  # Used to test the deduplication
  # of metrics when they come from the same executable file
  testserver-duplicate:
    build:
      context: ../..
      dockerfile: test/integration/components/testserver/Dockerfile_duplicate
    image: hatest-testserver-duplicate
    ports:
      - "18080:18080"
      - "18090:18090"
    environment:
      LOG_LEVEL: DEBUG

  rtestserver:
    image: ghcr.io/grafana/beyla-test/greeting-rust/0.0.4
    ports:
      - 8091:8090

  rtestserverssl:
    image: ghcr.io/grafana/beyla-test/greeting-rust-ssl/0.0.2
    ports:
      - 8491:8490
    environment:
      LOG_LEVEL: DEBUG

  pytestserverssl:
    build:
      context: ../..
      dockerfile: test/integration/components/pythonserver/Dockerfile_tls
    image: hatest-testserver-python-ssl
    ports:
      - 8381:8380

  pytestserver:
    build:
      context: ../..
      dockerfile: test/integration/components/pythonserver/Dockerfile_8083
    image: hatest-testserver-python
    ports:
      - 8183:8083

  ntestserverssl:
    build:
      context: ../..
      dockerfile: test/integration/components/nodejsserver/Dockerfile
    image: hatest-testserver-node-ssl
    command:
      - node
      - app_tls.js
    ports:
      - 3034:3033

  ntestserver:
    build:
      context: ../..
      dockerfile: test/integration/components/nodejsserver/Dockerfile
    image: hatest-testserver-node
    command:
      - node
      - app.js
    ports:
      - 3031:3030

  utestserver:
    image: ghcr.io/grafana/beyla-test/greeting-rails/0.0.2
    ports:
      - 3041:3040

  utestserverssl:
    image: ghcr.io/grafana/beyla-test/greeting-rails-ssl/0.0.2
    ports:
      - 3044:3043
        
  jtestserver:
    image: ghcr.io/grafana/beyla-test/greeting-java-jar/0.0.7
    ports:
      - "8086:8085"

  autoinstrumenter:
    build:
      context: ../..
      dockerfile: ./test/integration/components/beyla/Dockerfile
    command:
      - --config=/configs/instrumenter-config-multiexec.yml
    volumes:
      - ./configs/:/configs
      - ./system/sys/kernel/security:/sys/kernel/security
      - ../../testoutput:/coverage
      - ../../testoutput/run-multi:/var/run/beyla
    image: hatest-autoinstrumenter
    privileged: true # in some environments (not GH Pull Requests) you can set it to false and then cap_add: [ SYS_ADMIN ]
    pid: "host"
    environment:
      GOCOVERDIR: "/coverage"
      BEYLA_OTEL_METRICS_FEATURES: "application,application_span"
      BEYLA_TRACE_PRINTER: "text"
      BEYLA_METRICS_INTERVAL: "10ms"
      BEYLA_BPF_BATCH_TIMEOUT: "10ms"
      BEYLA_LOG_LEVEL: "DEBUG"
      BEYLA_BPF_DEBUG: "TRUE"
      BEYLA_HOSTNAME: "beyla"
      BEYLA_INTERNAL_METRICS_PROMETHEUS_PORT: 8999
      BEYLA_INTERNAL_METRICS_PROMETHEUS_PATH: /metrics
      BEYLA_BPF_DISABLE_BLACK_BOX_CP: "${BEYLA_BPF_DISABLE_BLACK_BOX_CP}"
      BEYLA_BPF_CONTEXT_PROPAGATION: "${BEYLA_BPF_CONTEXT_PROPAGATION}"
      BEYLA_BPF_TC_L7_CP: "${BEYLA_BPF_TC_L7_CP}"
      BEYLA_BPF_TRACK_REQUEST_HEADERS: "${BEYLA_BPF_TRACK_REQUEST_HEADERS}"
      BEYLA_BPF_HIGH_REQUEST_VOLUME: 1
    ports:
      - "8999:8999"      

  # OpenTelemetry Collector
  otelcol:
    image: otel/opentelemetry-collector-contrib:0.104.0
    container_name: otel-col
    deploy:
      resources:
        limits:
          memory: 125M
    restart: unless-stopped
    command: [ "--config=/etc/otelcol-config/otelcol-config-4017.yml" ]
    volumes:
      - ./configs/:/etc/otelcol-config
    ports:
      - "4017"          # OTLP over gRPC receiver
      - "4018:4018"     # OTLP over HTTP receiver
      - "9464"          # Prometheus exporter
      - "8888"          # metrics endpoint
    depends_on:
      prometheus:
        condition: service_started

  # Prometheus
  prometheus:
    image: quay.io/prometheus/prometheus:v2.55.1
    container_name: prometheus
    command:
      - --config.file=/etc/prometheus/prometheus-config.yml
      - --web.enable-lifecycle
      - --web.route-prefix=/
      - --log.level=debug
    volumes:
      - ./configs/:/etc/prometheus
    ports:
      - "9090:9090"

  jaeger:
    image: jaegertracing/all-in-one:1.57
    ports:
      - "16686:16686" # Query frontend
      - "4317:4317"   # OTEL GRPC traces collector
      - "4318:4318"   # OTEL HTTP traces collector
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - LOG_LEVEL=debug


# curl http://localhost:16686/api/services
# curl http://localhost:16686/api/traces?service=testserver
