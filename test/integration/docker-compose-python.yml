version: '3.8'

services:
  testserver:
    build:
      context: ../..
      dockerfile: test/integration/components/pythonserver/Dockerfile${TESTSERVER_DOCKERFILE_SUFFIX}
    image: hatest-testserver-python
    ports:
      - "${TEST_SERVICE_PORTS}"
    depends_on:
      otelcol:
        condition: service_started

  autoinstrumenter:
    build:
      context: ../..
      dockerfile: ./test/integration/components/beyla/Dockerfile
    volumes:
      - ./configs/:/configs
      - ./system/sys/kernel/security:/sys/kernel/security
      - ../../testoutput:/coverage
      - ../../testoutput/run-python:/var/run/beyla
    image: hatest-autoinstrumenter
    privileged: true # in some environments (not GH Pull Requests) you can set it to false and then cap_add: [ SYS_ADMIN ]
    network_mode: "service:testserver"
    pid: "service:testserver"
    environment:
      BEYLA_CONFIG_PATH: "/configs/instrumenter-config-java.yml"
      GOCOVERDIR: "/coverage"
      BEYLA_TRACE_PRINTER: "text"
      BEYLA_OPEN_PORT: "${BEYLA_OPEN_PORT}"
      BEYLA_DISCOVERY_POLL_INTERVAL: 500ms
      BEYLA_EXECUTABLE_NAME: "${BEYLA_EXECUTABLE_NAME}"
      BEYLA_SERVICE_NAMESPACE: "integration-test"
      BEYLA_METRICS_INTERVAL: "10ms"
      BEYLA_BPF_BATCH_TIMEOUT: "10ms"
      BEYLA_LOG_LEVEL: "DEBUG"
      BEYLA_BPF_DEBUG: "TRUE"
      BEYLA_HOSTNAME: "beyla"
      BEYLA_BPF_HTTP_REQUEST_TIMEOUT: "5s"
      BEYLA_PROCESSES_INTERVAL: "100ms"
      BEYLA_OTEL_METRICS_FEATURES: "application,application_process,application_span,application_service_graph"
    depends_on:
      testserver:
        condition: service_started

  # OpenTelemetry Collector
  otelcol:
    image: otel/opentelemetry-collector-contrib:0.104.0
    container_name: otel-col
    deploy:
      resources:
        limits:
          memory: 125M
    restart: unless-stopped
    command: [ "--config=/etc/otelcol-config/otelcol-config.yml" ]
    volumes:
      - ./configs/:/etc/otelcol-config
    ports:
      - "4317"          # OTLP over gRPC receiver
      - "4318:4318"     # OTLP over HTTP receiver
      - "9464"          # Prometheus exporter
      - "8888"          # metrics endpoint
    depends_on:
      prometheus:
        condition: service_started

  # Prometheus
  prometheus:
    image: quay.io/prometheus/prometheus:v2.55.1
    container_name: prometheus
    command:
      - --config.file=/etc/prometheus/prometheus-config.yml
      - --web.enable-lifecycle
      - --web.route-prefix=/
    volumes:
      - ./configs/:/etc/prometheus
    ports:
      - "9090:9090"
